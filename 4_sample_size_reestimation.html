<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Sample Size Re-Estimation</title>

<script src="site_libs/header-attrs-2.27/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />
<link href="site_libs/academicons-1.9.1/css/academicons.css" rel="stylesheet" />

<link rel="icon" type="image/png" href="./files/favicon.ico"/>

<script type="text/javascript">
function setBrand() {
document.getElementsByClassName("navbar-brand")[0].href="https://www.alexkaizer.com";
}
window.onload = setBrand;
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Alex Kaizer</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Short Course
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="0_intro.html">Intro and Welcome</a>
    </li>
    <li>
      <a href="1_intro_clinical_trials.html">Basics of Clinical Trials</a>
    </li>
    <li>
      <a href="2_intro_bayesian.html">Bayesian 101</a>
    </li>
    <li>
      <a href="3_interim_monitoring.html">Interim Monitoring</a>
    </li>
    <li>
      <a href="4_sample_size_reestimation.html">Sample Size Re-Estimation</a>
    </li>
    <li>
      <a href="5_adaptive_enrichment.html">Adaptive Enrichment</a>
    </li>
    <li>
      <a href="6_treatment_arm_selection.html">Treatment Arm Selection</a>
    </li>
    <li>
      <a href="7_adaptive_randomization.html">Adaptive Randomization</a>
    </li>
    <li>
      <a href="8_bayesian_information_sharing.html">Bayesian Information Sharing</a>
    </li>
    <li>
      <a href="9_master_protocols.html">Master Protocols</a>
    </li>
    <li>
      <a href="10_seamless_designs.html">Seamless Designs</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="mailto:alex.kaizer@cuanschutz.edu">
    <span class="fa fa-envelope fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://scholar.google.com/citations?user=ICpH74EAAAAJ&amp;hl=en">
    <span class="ai ai-google-scholar ai-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.alexkaizer.com/files/Alex_CV.pdf">
    <span class="ai ai-cv ai-lg"></span>
     
  </a>
</li>
<li>
  <a href="http://github.com/alexbiostats">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/AlexBiostats">
    <span class="fab fa-twitter fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/alex-kaizer/">
    <span class="fab fa-linkedin fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Sample Size Re-Estimation</h1>

</div>


<div id="overview" class="section level1">
<h1>Overview</h1>
<p>Oftentimes our power calculations represent our best guess at a
realistic treatment effect, but even using previous studies or extensive
clinical/scientific background can still result in uncertainty. In this
module we discuss how we can incorporate re-estimation procedures during
the trial to better ensure we enroll sufficient participants to detect
the observed effect.</p>
</div>
<div id="slide-deck" class="section level1">
<h1>Slide Deck</h1>
<iframe class="speakerdeck-iframe" style="border: 0px; background: rgba(0, 0, 0, 0.1) padding-box; margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 315;" frameborder="0" src="https://speakerdeck.com/player/4664c44f42e147b1bebe71608bda8c88" title="Sample Size Re-Estimation" allowfullscreen="true" data-ratio="1.7777777777777777">
</iframe>
<p> </p>
<p>You can also download the <a
href="./files/Slides/4_sample_size_reestimation.pptx">original
PowerPoint file</a>.</p>
</div>
<div id="code-examples-in-r" class="section level1">
<h1>Code Examples in R</h1>
<p>A selection of packages that may be helpful in implementing a
re-estimation procedure include:</p>
<ul>
<li><a
href="https://cran.r-project.org/web/packages/blindrecalc/index.html"><code>blindrecalc</code></a>:
a package for <em>blinded</em> sample re-estimation based on estimating
nuisance parameters</li>
<li><a href="https://www.rpact.org/"><code>rpact</code></a>: a package
for confirmatory adaptive clinical trial design, simulation, and
analysis; includes functions for combination testing for use in
unblinded designs</li>
<li><a
href="https://keaven.github.io/gsDesign/"><code>gsDesign</code></a>:
includes the <code>ssrCP()</code> function for unblinded re-estimation
based on conditional power</li>
<li><a
href="https://cran.r-project.org/web/packages/esDesign/"><code>esDesign</code></a>:
looks at adaptive enrichment designs with sample size re-estimation</li>
</ul>
<div id="blinded-example-with-binary-outcome" class="section level2">
<h2>Blinded Example with Binary Outcome</h2>
<p>In our first example we observe how the <code>blindrecalc</code>
package can be used for a study with a binary outcome. We will use a
chi-squared test as our motivating example, largely following the steps
from their helpful <a
href="https://journal.r-project.org/articles/RJ-2022-001/RJ-2022-001.pdf">R
Journal paper</a>.</p>
<p>First we set up our design as the chi-squared test using
<code>setupChiSquare()</code>. In this example we are testing a
one-sided hypothesis where <span class="math inline">\(H_1\colon p_1
&gt; p_2\)</span> with <span
class="math inline">\(\alpha=0.025\)</span>, <span
class="math inline">\(\beta=0.2\)</span> (i.e., power of 80%), and we
are interested in detecting a difference between two groups of 20%
(i.e., <span class="math inline">\(\delta=0.2\)</span>).</p>
<p>We can then estimate the number needed in a fixed sample design using
<code>n_fix()</code>. Here the nuisance parameter represents the average
of the two groups. We can then estimate the <span
class="math inline">\(N\)</span> needed overall with <span
class="math inline">\(N/2\)</span> in each randomized group to detect a
difference of 20%.</p>
<pre class="r"><code>library(blindrecalc)

# Compare basic functions
design &lt;- setupChiSquare(alpha = 0.025, beta = 0.2, delta = 0.2, alternative = &quot;greater&quot;)
n_fix(design, nuisance = c(0.2, 0.3, 0.4, 0.5))</code></pre>
<pre><code>## [1] 124 164 186 194</code></pre>
<p>We can verify these sample sizes are analogous to the
<code>power.prop.test()</code> function in base R:</p>
<pre class="r"><code>### Check that power.prop.test matches n_fix (which it does)
## round up N for each group, multiple by 2 to match overall sample size from n_fix

# nuisance 0.2
a1 &lt;- ceiling(power.prop.test(p1=0.1,p2=0.3,sig.level=0.025,power=0.8, alternative=&#39;o&#39;)$n)*2

# nuisance 0.3
a2 &lt;- ceiling(power.prop.test(p1=0.2,p2=0.4,sig.level=0.025,power=0.8, alternative=&#39;o&#39;)$n)*2

# nuisance 0.4
a3 &lt;- ceiling(power.prop.test(p1=0.3,p2=0.5,sig.level=0.025,power=0.8, alternative=&#39;o&#39;)$n)*2

# nuisance 0.5
a4 &lt;- ceiling(power.prop.test(p1=0.4,p2=0.6,sig.level=0.025,power=0.8, alternative=&#39;o&#39;)$n)*2

# print sample sizes
c(a1,a2,a3,a4)</code></pre>
<pre><code>## [1] 124 164 186 194</code></pre>
<p>Let’s focus on the <code>nusiance=0.2</code> case. We can examine the
impact on our design if we observe other nuisance parameters even though
we anticipated 0.2. The <code>toer()</code> function allows us to
estimate the type I error rate we may encounter if we do or do not use
blinded re-estimation:</p>
<pre class="r"><code>design &lt;- setupChiSquare(alpha = 0.025, beta = 0.2, delta = 0.2, alternative = &quot;greater&quot;)
n &lt;- n_fix(design, nuisance = 0.2) # N = 124 total (62 per group)
p &lt;- seq(0.2, 0.6, by = 0.1)
toer_fix &lt;- toer(design, n1 = n, nuisance = p, recalculation = FALSE)
toer_ips &lt;- toer(design, n1 = n/2, nuisance = p, recalculation = TRUE)

t1e_tab &lt;- rbind( &quot;No SSR&quot; = toer_fix, &quot;SSR at 1/2 Enrolled&quot; = toer_ips)
colnames(t1e_tab) &lt;- p
t1e_tab</code></pre>
<pre><code>##                            0.2        0.3        0.4        0.5        0.6
## No SSR              0.02366058 0.02484306 0.02701163 0.02943799 0.02701163
## SSR at 1/2 Enrolled 0.02544561 0.02536076 0.02484492 0.02565171 0.02484492</code></pre>
<p>By comparing these type I error rates, we see that there can be an
inflation to our desired <span
class="math inline">\(\alpha=0.025\)</span> due to observing different
averages between our two groups (i.e., the nuisance parameters reflected
by the column headers). With blinded SSR, we see better control of the
type I error rate.</p>
<p>We can use the similar <code>pow()</code> to estimate the power under
our design with varying nuisance parameters:</p>
<pre class="r"><code>pow_fix &lt;- pow(design, n1 = n, nuisance = p, recalculation = FALSE)
pow_ips &lt;- pow(design, n1 = n/2, nuisance = p, recalculation = TRUE)

pow_tab &lt;- rbind( &quot;No SSR&quot; = pow_fix, &quot;SSR at 1/2 Enrolled&quot; = pow_ips)
colnames(pow_tab) &lt;- p
pow_tab</code></pre>
<pre><code>##                           0.2       0.3      0.4       0.5      0.6
## No SSR              0.8100375 0.6892655 0.641467 0.6381293 0.641467
## SSR at 1/2 Enrolled 0.7871930 0.7933507 0.794409 0.7994804 0.794409</code></pre>
<p>For power we see that SSR maintains approximately 80% power, but
without SSR the power decreases as or nuisance parameter grows.</p>
<p>We can also plot the distribution of sample sizes that would occur at
different nuisance parameters to evaluate our potential risk of having a
much larger sample size:</p>
<pre class="r"><code>n_dist(design, n1 = n/2, nuisance = p, plot = TRUE)</code></pre>
<p><img src="4_sample_size_reestimation_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre><code>##          p = 0.2  p = 0.3  p = 0.4  p = 0.5  p = 0.6
## Min.     62.0000  78.0000 122.0000 154.0000 122.0000
## 1st Qu. 104.0000 148.0000 178.0000 192.0000 178.0000
## Median  122.0000 166.0000 188.0000 194.0000 188.0000
## Mean    122.1816 160.6994 184.1047 191.8221 184.1047
## 3rd Qu. 136.0000 174.0000 192.0000 194.0000 192.0000
## Max.    184.0000 194.0000 194.0000 194.0000 194.0000</code></pre>
<p>In this figure above we see that if our nuisance parameter is
actually 0.2 as assumed for the power calculation, or sample size
re-estimation could range from 62 to 184 versus our planned <span
class="math inline">\(N=124\)</span>. However, this does assume we allow
for sample size reductions and have no limit on the maximum increase. If
our guess of the nuisance parameter is 0.5, we see the largest increase
in our expected sample size up to 191.8, with a range of 154 to 194.</p>
</div>
<div id="unblinded-conditional-power-example-with-binary-outcome"
class="section level2">
<h2>Unblinded Conditional Power Example with Binary Outcome</h2>
<p>The <code>gsDesign</code> package includes the <code>ssrCP()</code>
which allows us to implement an <em>unblinded</em> sample size
re-estimation procedure. Here we continue our previous example using a
binary outcome. In this case we will incorporate traditional group
sequential O’Brien-Fleming boundaries for interim monitoring for
efficacy. This means our sample size will also be adjusted relative to a
fixed design to account for the use of the traditional GSD (this is in
contrast to alpha-spending boundaries that are OBF-like, where the
sample size remains fixed).</p>
<p>First, we must establish the design type based on the
<code>gsDesign()</code> function before extending to a conditional power
design with <code>ssrCP()</code>:</p>
<pre class="r"><code>library(gsDesign) # load package

x &lt;- gsDesign(
  k = 2, # number of analyses planned, including interim and final
  n.fix = 196, # sample size for a fixed design with no interim
  timing = 0.5, # timing of interm analyses 
  test.type=2, # 6 options covering one- vs. two-sided and symmetric vs. asymmetric boundaries; 2 is a two-sided symmetric approach
  alpha = 0.025, # one-sided type I error rate
  beta = 0.2, # type II error rate (i.e., power=1-beta)
  delta0 = 0, # null hypothesis parameter (i.e., no difference)
  delta1 = 0.2, # alternative hypothesis parameter (i.e., difference we wish to detect)
  sfu=&#39;OF&#39; ) # alpha-spending for efficacy monitoring

# plot stopping boundaries
plot(x)</code></pre>
<p><img src="4_sample_size_reestimation_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The plot shows our stopping boundaries for our two-sided test, with
the final critical value being 1.98 (versus 1.96 in a fixed design
without interim monitoring), as well as an increase from <span
class="math inline">\(N=196\)</span> to <span
class="math inline">\(N=198\)</span>.</p>
<p>We can then extend this design to a conditional power design based on
an observed test statistic at the end of our first stage. Here we assume
we observed <span class="math inline">\(Z=1.6\)</span>:</p>
<pre class="r"><code># extend design to a conditional power design
xx &lt;- ssrCP(x = x, # provide design used
            z1 = 1.6, # enter observed test statistic
            overrun = 0, # can note how many participants are enrolled but not included in the interim analysis
            beta = 0.2, # targeted type II error for SSR (i.e., targeted power=1-beta)
            cpadj = c(0.5,0.8), # range of conditional powers for which SSR is to be performed, otherwise N from original design used
            maxinc = 2, # argument limiting maximum fold-increase from planned max N (e.g., 2 times)
            z2 = z2NC) # combination function to combine stage 1 and stage 2 results; z2NC=inverse normal combination test, z2Z=sufficient stat for complete data, z2Fisher=Fisher&#39;s combination test

# show immediately relevant information
xx$dat</code></pre>
<pre><code>##    z1      z2       n2        CP     theta      delta
## 1 1.6 1.19651 259.0207 0.6567062 0.1609988 0.03219977</code></pre>
<p>From the <code>ssrCP</code> documentation, we see these values
represent:</p>
<ul>
<li>z1: input z1 values,</li>
<li>z2: computed cutoffs for the standard normal test statistic based
solely on stage 2 data</li>
<li>n2: stage 2 sample size (however, based on other functions I believe
this may be the maximum sample size to enroll, so we need to take
n2-n1)</li>
<li>CP: stage 2 conditional power</li>
<li>theta: standardize effect size used for conditional power
calculation</li>
<li>delta: the natural parameter value corresponding to theta The
relation between theta and delta is determined by the delta0 and delta1
values from x: delta = delta0 + theta(delta1-delta0).</li>
</ul>
<p>The most important summary is the re-estimated sample size of <span
class="math inline">\(N=259.0207\)</span> which rounds up to <span
class="math inline">\(N=260\)</span>, resulting in a need to enroll
<span class="math inline">\(N_2=260-99=161\)</span> in stage 2 instead
of the original <span class="math inline">\(N_2 = 198-99=99\)</span>.
Overall, this results in a total sample size of <span
class="math inline">\(N_1+N_2=99+161=260\)</span>, which is less than
the two times inflation allowed by <code>maxinc=2</code> (i.e., up to
<span class="math inline">\(198\times2 = 396\)</span> is allowed).</p>
<p>The other useful summary is the <code>z2=1.19651</code>, which
represents that we need to observe a test statistic at least this large
for our inverse normal combination test to be significant.</p>
<p>If we assume we enroll the 161 additional participants and observe
<span class="math inline">\(Z_2=1.3\)</span>, we would have a normal
combination test of</p>
<p><span class="math display">\[ \frac{Z_1 + Z_2}{\sqrt{2}} = \frac{1.6
+1.3}{\sqrt{2}} = 2.05 &gt; 1.96 = Z_{0.975} = Z_{1-\alpha/2}
\]</span></p>
<p>Therefore, we would reject the null hypothesis and conclude we found
an effect.</p>
</div>
</div>
<div id="simulation-study" class="section level1">
<h1>Simulation Study</h1>
<p>For our simulation study, let’s assume we are interested in designing
a study where we wish to reduce the rate of an adverse event by
exploring a new approach to a procedure:</p>
<ul>
<li><span class="math inline">\(H_0\colon p_1 = p_2\)</span> versus
<span class="math inline">\(H_1\colon p_1 &lt; p_2\)</span> (i.e.,
one-sided hypothesis)</li>
<li><span class="math inline">\(p_1 = p_{trt} = 0.1\)</span> and <span
class="math inline">\(p_2 = p_{con} = 0.25\)</span> for our alternative
hypothesis of interest (i.e., reducing the rate of adverse events from
25% to 10%)</li>
<li><span class="math inline">\(\alpha=0.025\)</span></li>
<li><span class="math inline">\(\beta=0.8\)</span></li>
</ul>
<p>For a fixed sample design, using <code>power.prop.test()</code>, we
can identify our sample size to enroll:</p>
<pre class="r"><code>power.prop.test(p1=0.1,p2=0.25,sig.level=0.025,power=0.8, alternative=&#39;o&#39;)</code></pre>
<pre><code>## 
##      Two-sample comparison of proportions power calculation 
## 
##               n = 99.54016
##              p1 = 0.1
##              p2 = 0.25
##       sig.level = 0.025
##           power = 0.8
##     alternative = one.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>Given <span class="math inline">\(n=100\)</span> per arm, we would
plan for a study enrolling a total of <span
class="math inline">\(N_{total}=200\)</span>.</p>
<p>We will evaluate five scenarios to determine the effect of sample
size re-estimation:</p>
<ul>
<li>Scenario 1: Null with <span class="math inline">\(p_1 = p_{trt} =
0.25\)</span> and <span class="math inline">\(p_2 = p_{con} =
0.25\)</span></li>
<li>Scenario 2: Null with <span class="math inline">\(p_1 = p_{trt} =
0.175\)</span> and <span class="math inline">\(p_2 = p_{con} =
0.175\)</span>, where the null rate is the nuisance parameter (i.e.,
<span class="math inline">\(\frac{0.1+0.25}{2}=0.175}\)</span>)</li>
<li>Scenario 3: Alternative with <span class="math inline">\(p_1 =
0.1\)</span> and <span class="math inline">\(p_2 = 0.25\)</span></li>
<li>Scenario 4: Alternative with <span class="math inline">\(p_1 =
0.15\)</span> and <span class="math inline">\(p_2 = 0.25\)</span></li>
<li>Scenario 5: Alternative with <span class="math inline">\(p_1 =
0.15\)</span> and <span class="math inline">\(p_2 = 0.30\)</span> (i.e.,
maintaining the <span class="math inline">\(\delta\)</span> but for
different effects)</li>
</ul>
<div id="blinded-re-estimation-with-binary-outcome-simulation"
class="section level2">
<h2>Blinded Re-estimation with Binary Outcome Simulation</h2>
<p>We first implement our blinded re-estimation procedure. We will
compare three strategies:</p>
<ol style="list-style-type: decimal">
<li>Blinded SSR where we will allow for a smaller than planned sample
size if indicated (i.e., if stage 2 needs fewer than 100 more
participants, we will enroll that number)</li>
<li>Blinded SSR where we will continue with the planned sample size if
the re-estimation indicates fewer participants could be needed (i.e., if
stage 2 needs fewer than 100 more participants, we will still enroll
100)</li>
<li>A fixed sample design with no SSR</li>
</ol>
<p>The code is hidden, but can be shown if desired. We will summarize
the rejection rate and average (SD) sample size across 1,000 simulation
trials.</p>
<pre class="r fold-hide"><code>sim_list &lt;- list( c(0.25, 0.25), c(0.175,0.175), c(0.1, 0.25), c(0.15, 0.25), c(0.15, 0.3))

# Create objects to store results in
blinded_res &lt;- blinded_n2_res &lt;- fixed_res &lt;- matrix(nrow=5, ncol=3, dimnames = list(c(&#39;Null 25 v 25&#39;,&#39;Null 17.5 v 17.5&#39;,&#39;Alt 10 v 25&#39;,&#39;Alt 15 v 25&#39;,&#39;Alt 15 v 30&#39;), c(&#39;Rej_Rate&#39;,&#39;ESS&#39;,&#39;ESS_SD&#39;)))

# Set simulation parameters
n &lt;- 200 # total sample size based on fixed sample
n1 &lt;- 100 # sample size to enroll for stage 1
delta &lt;- 0.15 # expected effect size under H1 from power calculation
r &lt;- 1 # randomization ratio (e.g., 1:1)
nsim &lt;- 1000

###
# simulate method with SSR allowing for smaller than expected N
for( combo in 1:length(sim_list) ){
  
  # initialize object to save results in
  simres &lt;- data.frame( p=rep(NA,nsim), n=rep(NA,nsim) )
  
  pt &lt;- sim_list[[combo]][1]
  pc &lt;- sim_list[[combo]][2]
  
  # loop through nsim simulations
  for( i in 1:nsim ){
    set.seed(i) # set seed for reproducibility
    
    # simulate stage 1
    trt &lt;- rbinom(n=n1/2, size=1, prob=pt)
    con &lt;- rbinom(n=n1/2, size=1, prob=pc)
    
    # blinded re-estimation
    p0 &lt;- sum(trt,con) / n1
    
    # assuming same delta, estimate new pt and pc
    pt_n1 &lt;- p0 - delta*(r/(1+r))
    pc_n1 &lt;- p0 + delta*(r/(1+r))
    
    # use power.prop.test based on re-estimated pt (p1) and pc (p2)
    n_rest &lt;- 2*ceiling(power.prop.test(p1=pt_n1,p2=pc_n1,sig.level=0.025,power=0.8,alternative=&#39;o&#39;)$n)
    n2 &lt;- n_rest - n1 # estimate sample size needed for remainder
    if( n2 &lt; 0 ){ n2 &lt;- 0 } # if sufficient sample size already, set to 0
    
    # simulate stage 2 data
    trt &lt;- c(trt, rbinom(n=n2/2, size=1, prob=pt) )
    con &lt;- c(con, rbinom(n=n2/2, size=1, prob=pc) )
    
    # final analysis, save results
    res &lt;- prop.test(x=c(sum(trt),sum(con)), n=c(length(trt),length(con)), alternative = &#39;less&#39;)    # defined as less based on order of data entered for trt and con
    simres[i,] &lt;- c(round(res$p.value,4), n1+n2 )
  }
  
  blinded_res[combo,] &lt;- c( mean(simres$p &lt; 0.025), round(mean(simres$n),1), round(sd(simres$n),1))
  
}


###
# simulate method with SSR but enrolling at least (N-N1) in stage 2 (i.e., not allowing fewer participants)
for( combo in 1:length(sim_list) ){
  
  # initialize object to save results in
  simres &lt;- data.frame( p=rep(NA,nsim), n=rep(NA,nsim) )
  
  pt &lt;- sim_list[[combo]][1]
  pc &lt;- sim_list[[combo]][2]
  
  # loop through nsim simulations
  for( i in 1:nsim ){
    set.seed(i) # set seed for reproducibility
    
    # simulate stage 1
    trt &lt;- rbinom(n=n1/2, size=1, prob=pt)
    con &lt;- rbinom(n=n1/2, size=1, prob=pc)
    
    # blinded re-estimation
    p0 &lt;- sum(trt,con) / n1
    
    # assuming same delta, estimate new pt and pc
    pt_n1 &lt;- p0 - delta*(r/(1+r))
    pc_n1 &lt;- p0 + delta*(r/(1+r))
    
    # use power.prop.test based on re-estimated pt (p1) and pc (p2)
    n_rest &lt;- 2*ceiling(power.prop.test(p1=pt_n1,p2=pc_n1,sig.level=0.025,power=0.8,alternative=&#39;o&#39;)$n)
    n2 &lt;- n_rest - n1 # estimate sample size needed for remainder
    if( n2 &lt; (n-n1) ){ n2 &lt;- (n-n1) } # enroll at least (n-n1)
    
    # simulate stage 2 data
    trt &lt;- c(trt, rbinom(n=n2/2, size=1, prob=pt) )
    con &lt;- c(con, rbinom(n=n2/2, size=1, prob=pc) )
    
    # final analysis, save results
    res &lt;- prop.test(x=c(sum(trt),sum(con)), n=c(length(trt),length(con)), alternative = &#39;less&#39;)    # defined as less based on order of data entered for trt and con
    simres[i,] &lt;- c(round(res$p.value,4), n1+n2 )
  }
  
  blinded_n2_res[combo,] &lt;- c( mean(simres$p &lt; 0.025), round(mean(simres$n),1), round(sd(simres$n),1))
  
}


###
# simulate fixed sample design for comparison
for( combo in 1:length(sim_list) ){
  
  # initialize object to save results in
  simres &lt;- data.frame( p=rep(NA,nsim), n=rep(NA,nsim) )
  
  pt &lt;- sim_list[[combo]][1]
  pc &lt;- sim_list[[combo]][2]
  
  # loop through nsim simulations
  for( i in 1:nsim ){
    set.seed(i) # set seed for reproducibility
    
    # simulate stage 1
    trt &lt;- rbinom(n=n1/2, size=1, prob=pt)
    con &lt;- rbinom(n=n1/2, size=1, prob=pc)
    
    # simulate stage 2 after stage 1 to keep same random sequence
    trt2 &lt;- rbinom(n=(n-n1)/2, size=1, prob=pt)
    con2 &lt;- rbinom(n=(n-n1)/2, size=1, prob=pc)

    # final analysis
    res &lt;- prop.test(x=c(sum(c(trt,trt2)),sum(c(con,con2))), n=c(n/2,n/2), alternative = &#39;less&#39;)    # defined as less based on order of data entered for trt and con
    simres[i,] &lt;- c(round(res$p.value,4), n )
  }

  fixed_res[combo,] &lt;- c( mean(simres$p &lt; 0.025), round(mean(simres$n),1), round(sd(simres$n),1))
  
} 

# Format results
library(kableExtra)
kbl_tab &lt;- cbind(fixed_res,blinded_res,blinded_n2_res)

kbl_tab %&gt;%
  kbl(col.names=c(&#39;Scenario&#39;,rep(c(&#39;Rejection Rate&#39;,&#39;ESS&#39;,&#39;ESS SD&#39;), 3)) ) %&gt;%
  kable_classic() %&gt;%
  add_header_above(c(&quot; &quot;=1, &quot;Fixed Sample&quot;=3, &quot;SSR with Lower N2&quot;=3, &quot;SSR with At Least N2&quot;=3))</code></pre>
<table class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
Fixed Sample
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
SSR with Lower N2
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
SSR with At Least N2
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Scenario
</th>
<th style="text-align:right;">
Rejection Rate
</th>
<th style="text-align:right;">
ESS
</th>
<th style="text-align:right;">
ESS SD
</th>
<th style="text-align:right;">
Rejection Rate
</th>
<th style="text-align:right;">
ESS
</th>
<th style="text-align:right;">
ESS SD
</th>
<th style="text-align:right;">
Rejection Rate
</th>
<th style="text-align:right;">
ESS
</th>
<th style="text-align:right;">
ESS SD
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Null 25 v 25
</td>
<td style="text-align:right;">
0.020
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.022
</td>
<td style="text-align:right;">
257.3
</td>
<td style="text-align:right;">
31.0
</td>
<td style="text-align:right;">
0.022
</td>
<td style="text-align:right;">
258.1
</td>
<td style="text-align:right;">
29.2
</td>
</tr>
<tr>
<td style="text-align:left;">
Null 17.5 v 17.5
</td>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.023
</td>
<td style="text-align:right;">
197.7
</td>
<td style="text-align:right;">
35.1
</td>
<td style="text-align:right;">
0.021
</td>
<td style="text-align:right;">
212.9
</td>
<td style="text-align:right;">
18.6
</td>
</tr>
<tr>
<td style="text-align:left;">
Alt 10 v 25
</td>
<td style="text-align:right;">
0.754
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.734
</td>
<td style="text-align:right;">
198.3
</td>
<td style="text-align:right;">
33.9
</td>
<td style="text-align:right;">
0.784
</td>
<td style="text-align:right;">
212.7
</td>
<td style="text-align:right;">
18.5
</td>
</tr>
<tr>
<td style="text-align:left;">
Alt 15 v 25
</td>
<td style="text-align:right;">
0.368
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.384
</td>
<td style="text-align:right;">
218.7
</td>
<td style="text-align:right;">
34.2
</td>
<td style="text-align:right;">
0.394
</td>
<td style="text-align:right;">
225.3
</td>
<td style="text-align:right;">
24.8
</td>
</tr>
<tr>
<td style="text-align:left;">
Alt 15 v 30
</td>
<td style="text-align:right;">
0.689
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.748
</td>
<td style="text-align:right;">
239.8
</td>
<td style="text-align:right;">
33.0
</td>
<td style="text-align:right;">
0.762
</td>
<td style="text-align:right;">
242.0
</td>
<td style="text-align:right;">
28.9
</td>
</tr>
</tbody>
</table>
<p>From these simulation results we can see that:</p>
<ul>
<li>Without some form of futility testing, the blinded SSR methods lead
to increased sample sizes in the null scenario with 25% versus 25%, as
well as slightly higher type I error rates than the fixed sample
design.</li>
<li>If the null scenario response reflects the nuisance parameter, we
still see slightly higher type I error rates with SSR. However, the ESS
increase is less large, likely because the effect went closer to 0. This
may indicate that less prevalent outcomes are less affected by the null
scenario with blinded re-estimation.</li>
<li>If we encounter the effect sizes used in the power analysis, we see
that SSR that enrolls <em>at least</em> the <span
class="math inline">\(N_{total}=200\)</span> of the fixed sample design
increases power by allowing for larger sample sizes. On average, across
all 1000 simulated trials, the average sample size was 212.7
(SD=18.5).</li>
<li>If we encounter an underpowered scenario, we see that the SSR
methods also lead to an increased SSR but only slightly higher power.
This suggests that either unblinded re-estimation processes or
potentially futility monitoring could further improve performance.</li>
<li>Finally, if we observe the same <span
class="math inline">\(\delta=0.15\)</span> but at higher observed rates
(<span class="math inline">\(p_{trt}=0.15\)</span> and <span
class="math inline">\(p_{con}=0.30\)</span>), our blinded SSR increases
power by 5.9 to 7.3% by allowing our sample size to increase based on
the higher nuisance paramter (i.e., <span
class="math inline">\(\frac{0.15+0.3}{2}=0.225\)</span>).</li>
</ul>
</div>
<div id="unblinded-re-estimation-with-binary-outcome-simulation"
class="section level2">
<h2>Unblinded Re-estimation with Binary Outcome Simulation</h2>
<p>We can compare the results from our blinded SSR approach with an
approach using unblinded SSR approaches. In this simulation we
compare:</p>
<ul>
<li>An approach using conditional power estimated from
<code>gsDesign::ssrCP()</code>, where we assume that the second stage
must have at least 100 participants but could increase to 200
participants (i.e., we don’t allow fewer than expected participants in
stage 2). This approach uses the inverse normal combination test based
on the p-values from the two-sample test of proportions.</li>
<li>An approach that unblinds the control arm to use in re-estimating
the <code>power.prop.test()</code> calculation for a decrease of 15% in
the treatment arm. If the control arm has a response rate less than 15%,
we stop for futility and calculate the one-sided p-value to record for
futility. Otherwise, we allow the re-estimation to increase the sample
size from 100 up to 200. Since we do not unblind the treatment arm, in
this approach we evaluate the performance if we use the overall data for
our final test p-value.</li>
<li>A fixed sample design enrolling 200 total participants without
interim monitoring or re-estimation.</li>
</ul>
<p>The simulation code block is hidden, but can be shown for review.</p>
<pre class="r fold-hide"><code>library(gsDesign) # load library

# list of 5 simulation scenarios to mimic our blinded SSR
sim_list &lt;- list( c(0.25, 0.25), c(0.175,0.175), c(0.1, 0.25), c(0.15, 0.25), c(0.15, 0.3))

# Create objects to store results in
unblinded_res &lt;- unblinded_adhoc_res &lt;- fixed_res &lt;- matrix(nrow=5, ncol=3, dimnames = list(c(&#39;Null 25 v 25&#39;,&#39;Null 17.5 v 17.5&#39;,&#39;Alt 10 v 25&#39;,&#39;Alt 15 v 25&#39;,&#39;Alt 15 v 30&#39;), c(&#39;Rej_Rate&#39;,&#39;ESS&#39;,&#39;ESS_SD&#39;)))

# Set simulation parameters
delta &lt;- 0.15 # expected effect size under H1 from power calculation
r &lt;- 1 # randomization ratio (e.g., 1:1)
nsim &lt;- 1000

x &lt;- gsDesign(
  k = 2, 
  n.fix = 200, timing = 0.5, test.type=2,
  alpha = 0.025, beta = 0.2, delta0 = 0, delta1 = 0.15, sfu=&#39;OF&#39; ) 

n_fix &lt;- 200 # total sample size based on fixed sample
n1 &lt;- ceiling(x$n.I[1])
n &lt;- ceiling(x$n.I[2]) 

###
# simulate method with SSR using conditional power

for( combo in 1:length(sim_list) ){
  
  # initialize object to save results in
  simres_gs &lt;- data.frame( zcombined=rep(NA,nsim), n=rep(NA,nsim) )
  
  pt &lt;- sim_list[[combo]][1]
  pc &lt;- sim_list[[combo]][2]
  
  for( i in 1:nsim ){
    set.seed(i) # set seed for reproducibility
    
    # simulate stage 1
    trt &lt;- rbinom(n=n1/2, size=1, prob=pt)
    con &lt;- rbinom(n=n1/2, size=1, prob=pc)
    res_int &lt;- prop.test(x=c(sum(trt),sum(con)), n=c(length(trt),length(con)), alternative = &#39;less&#39;)$p.value
    
    # UNblinded re-estimation
    xx &lt;- ssrCP(x = x, z1 = qnorm(1-res_int), overrun = 0, beta = 0.2, cpadj = c(0.5,0.8), maxinc = 1.5, z2 = z2NC)
    n_rest &lt;- ceiling(xx$dat$n2) - n1
      n2 &lt;- n_rest
      n2 &lt;- if(n2 &lt;= 100){ 100 }else{n2} 
    if( res_int &lt; x$upper$prob[1,1] ){ 
      # final analysis, save results
      zcombined &lt;- qnorm(1-res_int) / sqrt(1)
      simres_gs[i,] &lt;- c(zcombined, n1+0)
    }else{
      # simulate stage 2 data
      trt2 &lt;- rbinom(n=n2/2, size=1, prob=pt)
      con2 &lt;- rbinom(n=n2/2, size=1, prob=pc)
      
      # final analysis, save results
      res &lt;- prop.test(x=c(sum(trt2),sum(con2)), n=c(length(trt2),length(con2)), alternative = &#39;less&#39;)$p.value
      
      zcombined &lt;- ( qnorm(1-res_int) + qnorm(1-res) ) / sqrt(2)
      
      simres_gs[i,] &lt;- c(zcombined, n1+n2)
    }
  }
  
  unblinded_res[combo,] &lt;- c( mean(simres_gs$zcombined &gt;= qnorm(1-(0.025))), round(mean(simres_gs$n),1), round(sd(simres_gs$n),1))

}

###
# somewhat ad hoc approach to unblinded SSR
# first stage is used to implement re-estimation; no decreases in stage 2; up to 200 (versus 100) otherwise stop for futility
for( combo in 1:length(sim_list) ){
  
  # set sample sizes based on fixed sample to initialize
  n &lt;- 200
  n1 &lt;- 100
  
  # initialize object to save results in
  simres_gs &lt;- data.frame( p=rep(NA,nsim), n=rep(NA,nsim) )
  
  pt &lt;- sim_list[[combo]][1]
  pc &lt;- sim_list[[combo]][2]
  
  for( i in 1:nsim ){
    set.seed(i) # set seed for reproducibility
    
    # simulate stage 1
    trt &lt;- rbinom(n=n1/2, size=1, prob=pt)
    con &lt;- rbinom(n=n1/2, size=1, prob=pc)
    res_int &lt;- prop.test(x=c(sum(trt),sum(con)), n=c(length(trt),length(con)), alternative = &#39;less&#39;)
    
    # UNblinded re-estimation, where we use the estimate of the control group and still power for a 0.15 decrease in treatment
    n_reest &lt;- if( mean(con) &lt;= 0.15 ){ 10000 }else{ ceiling(power.prop.test(p1=mean(con)-0.15,p2=mean(con),sig.level=0.025,power=0.8, alternative=&#39;o&#39;)$n)*2 }
    
    n2 &lt;- if( (n_reest - n1) &lt; 100 ){100}else{n_reest - n1}
    
      if( n2 &gt; 200 ){
      # ad hoc futility rule, save first stage result
      p &lt;- res_int$p.value
      simres_gs[i,] &lt;- c(p, n1+0)
    }else{
      # simulate stage 2 data
      trt2 &lt;- rbinom(n=n2/2, size=1, prob=pt)
      con2 &lt;- rbinom(n=n2/2, size=1, prob=pc)
      
      # final analysis, save results
      res &lt;- prop.test(x=c(sum(c(trt,trt2)),sum(c(con,con2))), n=c(length(c(trt,trt2)),length(c(con,con2))), alternative = &#39;less&#39;)
      p &lt;- res$p.value
  
      simres_gs[i,] &lt;- c(p, n1+n2)
    }
  }
  
  unblinded_adhoc_res[combo,] &lt;- c( mean(simres_gs$p &lt; 0.025), round(mean(simres_gs$n),1), round(sd(simres_gs$n),1))

}



###
# simulate fixed sample design for comparison
for( combo in 1:length(sim_list) ){
  
  # set sample sizes for fixed sample
  n &lt;- 200
  n1 &lt;- 100
  
  # initialize object to save results in
  simres &lt;- data.frame( p=rep(NA,nsim), n=rep(NA,nsim) )
  
  pt &lt;- sim_list[[combo]][1]
  pc &lt;- sim_list[[combo]][2]
  
  # loop through nsim simulations
  for( i in 1:nsim ){
    set.seed(i) # set seed for reproducibility
    
    # simulate stage 1
    trt &lt;- rbinom(n=n1/2, size=1, prob=pt)
    con &lt;- rbinom(n=n1/2, size=1, prob=pc)
    
    # simulate stage 2 after stage 1 to keep same random sequence
    trt2 &lt;- rbinom(n=(n-n1)/2, size=1, prob=pt)
    con2 &lt;- rbinom(n=(n-n1)/2, size=1, prob=pc)

    # final analysis
    res &lt;- prop.test(x=c(sum(c(trt,trt2)),sum(c(con,con2))), n=c(n/2,n/2), alternative = &#39;less&#39;)    # defined as less based on order of data entered for trt and con
    simres[i,] &lt;- c(round(res$p.value,4), n )
  }

  fixed_res[combo,] &lt;- c( mean(simres$p &lt; 0.025), round(mean(simres$n),1), round(sd(simres$n),1))
  
} 

# Format results
library(kableExtra)
kbl_tab &lt;- cbind(fixed_res,unblinded_res,unblinded_adhoc_res)

kbl_tab %&gt;%
  kbl(col.names=c(&#39;Scenario&#39;,rep(c(&#39;Rejection Rate&#39;,&#39;ESS&#39;,&#39;ESS SD&#39;), 3)) ) %&gt;%
  kable_classic() %&gt;%
  add_header_above(c(&quot; &quot;=1, &quot;Fixed Sample&quot;=3, &quot;SSR with CP&quot;=3, &quot;SSR Unblind Control&quot;=3))</code></pre>
<table class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
Fixed Sample
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
SSR with CP
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
SSR Unblind Control
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Scenario
</th>
<th style="text-align:right;">
Rejection Rate
</th>
<th style="text-align:right;">
ESS
</th>
<th style="text-align:right;">
ESS SD
</th>
<th style="text-align:right;">
Rejection Rate
</th>
<th style="text-align:right;">
ESS
</th>
<th style="text-align:right;">
ESS SD
</th>
<th style="text-align:right;">
Rejection Rate
</th>
<th style="text-align:right;">
ESS
</th>
<th style="text-align:right;">
ESS SD
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Null 25 v 25
</td>
<td style="text-align:right;">
0.020
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.010
</td>
<td style="text-align:right;">
203.9
</td>
<td style="text-align:right;">
11.7
</td>
<td style="text-align:right;">
0.022
</td>
<td style="text-align:right;">
212.6
</td>
<td style="text-align:right;">
39.0
</td>
</tr>
<tr>
<td style="text-align:left;">
Null 17.5 v 17.5
</td>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
203.7
</td>
<td style="text-align:right;">
13.4
</td>
<td style="text-align:right;">
0.022
</td>
<td style="text-align:right;">
170.3
</td>
<td style="text-align:right;">
49.1
</td>
</tr>
<tr>
<td style="text-align:left;">
Alt 10 v 25
</td>
<td style="text-align:right;">
0.754
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.716
</td>
<td style="text-align:right;">
198.7
</td>
<td style="text-align:right;">
46.0
</td>
<td style="text-align:right;">
0.740
</td>
<td style="text-align:right;">
212.6
</td>
<td style="text-align:right;">
39.0
</td>
</tr>
<tr>
<td style="text-align:left;">
Alt 15 v 25
</td>
<td style="text-align:right;">
0.368
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.335
</td>
<td style="text-align:right;">
206.4
</td>
<td style="text-align:right;">
30.9
</td>
<td style="text-align:right;">
0.378
</td>
<td style="text-align:right;">
212.6
</td>
<td style="text-align:right;">
39.0
</td>
</tr>
<tr>
<td style="text-align:left;">
Alt 15 v 30
</td>
<td style="text-align:right;">
0.689
</td>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.656
</td>
<td style="text-align:right;">
202.0
</td>
<td style="text-align:right;">
44.9
</td>
<td style="text-align:right;">
0.727
</td>
<td style="text-align:right;">
224.6
</td>
<td style="text-align:right;">
51.8
</td>
</tr>
</tbody>
</table>
<p>The simulation results indicate:</p>
<ul>
<li>That the fixed sample design is slightly conservative with type I
error of 2%, which is similar to the SSR with unblinded controls at
2.2%, although the sample size increases to an average of 212.6
(SD=39.0).</li>
<li>The SSR with conditional power is overly conservative, as seen by
the lower type I error rates and power compared to the fixed sample
design.</li>
<li>The SSR unblinded control shows the greatest improvement when the
control reference is higher than expected (i.e., 30% instead of 25%),
where power increases to 72.7% versus 68.9% for a fixed sample design.
However, the ESS does increase to 224.6 (SD=51.8) versus 200 for the
fixed sample design.</li>
<li>Some limitations in performance may be due to the fact that our
allowed increase is somewhat limited in stage 2 from 100 to 200. In
practice, if it was feasible to go higher we could likely improve our
power relative to a fixed sample design.</li>
</ul>
<p>While only a limited set of methods and scenarios with a binary
outcome, these results suggest the caution should be taken in
implementing sample size re-estimation since it can introduce
variability in our needed sample size while also potentially resulting
in limited gains in power or type I error performance relative to a
fixed sample design.</p>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Below are some references to highlight based on the slides and
code:</p>
<ul>
<li><p><a
href="https://www.fda.gov/regulatory-information/search-fda-guidance-documents/adaptive-design-clinical-trials-drugs-and-biologics-guidance-industry">FDA
Adaptive Design Clinical Trials for Drugs and Biologics Guidance for
Industry Guidance Document</a>: FDA guidance document on adaptive trial
elements</p></li>
<li><p><a
href="https://www.cambridge.org/core/journals/journal-of-clinical-and-translational-science/article/recent-innovations-in-adaptive-trial-designs-a-review-of-design-opportunities-in-translational-research/614EAFEA5E89CA035E82E152AF660E5D?utm_campaign=shareaholic&amp;utm_medium=copy_link&amp;utm_source=bookmark">Recent
innovations in adaptive trial designs: A review of design opportunities
in translational research</a>: 2023 review paper examining adaptive and
novel trial elements with included case studies</p></li>
<li><p><a
href="https://www.cambridge.org/core/journals/journal-of-clinical-and-translational-science/article/guidance-on-interim-analysis-methods-in-clinical-trials/5051FDCF5284970B3DB01FE609AAA4C2?utm_campaign=shareaholic&amp;utm_medium=copy_link&amp;utm_source=bookmark">Guidance
on interim analysis methods in clinical trials</a>: 2023 review paper
focusing on interim analyses in clinical trials with included case
studies</p></li>
<li><p><a
href="https://link.springer.com/book/10.1007/978-3-030-49528-2">Kieser,
Meinhard. <em>Methods and applications of sample size calculation and
Recalculation in clinical trials.</em> Springer, 2020.</a>: textbook
covering SSR methods and approaches</p></li>
</ul>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
