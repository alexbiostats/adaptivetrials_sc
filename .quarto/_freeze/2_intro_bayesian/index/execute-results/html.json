{
  "hash": "6682df0ba5e87e16fef103753a53d451",
  "result": {
    "markdown": "---\ntitle: \"Bayesian 101\"\ntoc: true\ntoc_float: true\ntoc-location: left\nformat:\n  html:\n    code-fold: show\n    code-overflow: wrap \n    code-tools: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n# Overview\n\nThis module covers a crash course in Bayesian statistics. While many adaptive trial elements can be done with frequentist methods, Bayesian methods provide additional flexibility. We will introduce the basics of the Bayesian approach to statistics and cover a brief example analysis of a clinical trial using Bayesian methods.\n\n# Slide Deck\n\n<iframe class=\"speakerdeck-iframe\" style=\"border: 0px; background: rgba(0, 0, 0, 0.1) padding-box; margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 315;\" frameborder=\"0\" src=\"https://speakerdeck.com/player/9e2562ed178d47419175ba3647883c01\" title=\"Bayesian 101\" allowfullscreen=\"true\" data-ratio=\"1.7777777777777777\">\n\n</iframe>\n\nÂ \n\nYou can also download the [original PowerPoint file](../files/Slides/2_intro_bayesian.pptx).\n\n# Code Examples in R\n\n## Software Options\n\nThere are lots of statistical packages and approaches that we can use to either run Bayesian models in R, or to connect R with external software to implement the models. Some options include:\n\n-   [`brms` package](https://paul-buerkner.github.io/brms/): implements the Stan programming language within R, syntax is similar to the `lme4` package, this is our focus for Bayesian examples\n-   [`rstan` and `rstanarm` packages](https://mc-stan.org/users/interfaces/rstan): implements the Stan programming language within R, `rstanarm` uses standard `glm` syntax, runs more quickly than `brms` since models are pre-compiled\n-   [`bayestestr` package](https://easystats.github.io/bayestestR/): can provide Bayes factors and works with `rstanarm`, `brms`, and `BayesFactor`\n-   [`R2jags`](https://cran.r-project.org/web/packages/R2jags/index.html), [`rjags`](https://cran.r-project.org/web/packages/rjags/index.html), [`runjags`](https://cran.r-project.org/web/packages/runjags/index.html) packages: implements [JAGS (just another Gibbs sampler)](https://mcmc-jags.sourceforge.io/) which allows for non-gradient sampling, JAGS is one of the \"original\" approaches for implementing Bayesian analyses via software (that I remember), can be a little clunkier than other options\n\nIt is worth noting that within each software distributions may use different parameterizations, so caution should be taken to ensure the desired prior values are used. For example, the normal distribution in JAGS uses the precision (i.e., $\\tau = \\frac{1}{\\sigma^2}$), whereas Stan uses the standard deviation (i.e., $\\sigma$).\n\nDr. Kruschke has a nice introduction to Bayesian textbook that includes some [instructions for installing software for Bayesian analyses](https://sites.google.com/site/doingbayesiandataanalysis/software-installation). You may also be interested in exploring the textbook for more background on Bayesian theory, methods, and implementation.\n\nAdditionally, Stata and SAS (e.g., PROC MCMC and PROC GENMOD) include Bayesian options. These are detailed in [\"A practical guide to adopting Bayesian analyses in clinical research\"](https://www.cambridge.org/core/journals/journal-of-clinical-and-translational-science/article/practical-guide-to-adopting-bayesian-analyses-in-clinical-research/CF6C017318CD5431C98EEFE37DBB6063?utm_campaign=shareaholic&utm_medium=copy_link&utm_source=bookmark) for step-by-step guidance on their implementation.\n\n## Linear Regression Code from [\"A practical guide to adopting Bayesian analyses in clinical research\"](https://www.cambridge.org/core/journals/journal-of-clinical-and-translational-science/article/practical-guide-to-adopting-bayesian-analyses-in-clinical-research/CF6C017318CD5431C98EEFE37DBB6063?utm_campaign=shareaholic&utm_medium=copy_link&utm_source=bookmark)\n\nThis section provides the code from the published paper in R. The dataset for the paper is included in the corresponding [GitHub repository hosted by Dr. Nichole Carlson](https://github.com/nichole-carlson/BayesianClinicalResearch), but can also be downloaded as CSV here for convenience: [drugtrial.csv](./files/drugtrial.csv).\n\nFor simplicity, we focus on comparing priors across simple linear regression models, but the [GitHub repository](https://github.com/nichole-carlson/BayesianClinicalResearch) includes examples for multiple linear regression and logistic regression models as well. In this example, we have a continuous outcome of time to readiness for discharge (in minutes) that are compared by two randomized treatment groups (sufentanil (new treatment) versus IV fentanyl).\n\nFirst, let's load our packages and read in our data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# CALL LIBRARIES\nlibrary(brms) #Bayesian modeling capabilities\nlibrary(bayestestR) #particular Bayesian tests\n\n# READ IN CLINICAL TRIAL DATA FROM PAPER\ntrial <- read.csv('../files/drugtrial.csv')\n\n### CHECK OUT TOP ROWS OF DATA\n## trial mini-data dictionary:\n# rowid: trial ID\n# in_phase_1_to_out_of_phase_2: time to readiness for discharge after arrival in PACU (minutes)\n# sex_n: sex of participant (1=female, 0=male)\n# groupn: randomized group (1=sufentanil, 0=IV fentanyl)\n# blockn: preoperative nerve block used (1=yes, 0=no)\n# proc_length_center: procedure length (minutes)\n\nhead(trial)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  rowid in_phase_1_to_out_of_phase_2 sex_n groupn blockn proc_length_center\n1     1                           60     1      0      0              -37.8\n2     2                           69     1      1      1              -10.8\n3     3                          102     1      1      0              -57.8\n4     4                          165     1      0      0               22.2\n5     5                          115     1      1      0              140.2\n6     6                          104     0      0      1               21.2\n```\n:::\n:::\n\n\n### Frequentist Simple Linear Regression\n\nFor comparison sake, we can first fit our frequentist simple linear regression using the `glm` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Syntax: <name of model object> <- glm(<outcome variable> ~ <predictor variable>, data = <datasetname>, family=<distribution corresponding to model type>) \nlin_reg <- glm(in_phase_1_to_out_of_phase_2 ~ groupn, \n               data=trial, \n               family='gaussian')\n\n# Syntax: summary(<model object>) - function to show model parameter estimates/results\nsummary(lin_reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = in_phase_1_to_out_of_phase_2 ~ groupn, family = \"gaussian\", \n    data = trial)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   94.364      5.289  17.842   <2e-16 ***\ngroupn         3.727      7.480   0.498     0.62    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 923.0682)\n\n    Null deviance: 59306  on 65  degrees of freedom\nResidual deviance: 59076  on 64  degrees of freedom\nAIC: 641.9\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n\n```{.r .cell-code}\n# Syntax: confint() - print confidence intervals in console\nconfint(lin_reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                2.5 %   97.5 %\n(Intercept)  83.99771 104.7296\ngroupn      -10.93236  18.3869\n```\n:::\n:::\n\n\n### brms Bayesian Simple Linear Regression Syntax\n\nThe general syntax for using `brm` is described below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Syntax: using brm function for Bayesian modeling\n#   <name of model object> <- brm(<outcome variable> ~ <predictor variable>, \n#            data = <datasetname>, \n#            family=<distribution corresponding to model type>,\n#            prior = c(set_prior(\"<distribution(mean,SD)\", class = \"<name>\")),\n#            seed = <value - for reproducibility>,\n#            init = <name of initial values list>,\n#            warmup = <sets the # of burn-in iterations (those that will be 'thrown out')>,\n#            iter = <# of total iterations for each chain including burn-in>\n#            chains = <# of chains>,\n#            cores = <#> to use for executing chains in parallel - for processing)\n```\n:::\n\n\nWe also will create a set of initial values to use for each our simple linear regressions below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set initial starting values for chains by creating a list, will be used for all simple linear regressions\n# Syntax: list(<model parameter> = <starting value>); be sure to list all parameters\ninits <- list(\n  Intercept = 0,\n  sigma     = 1,\n  beta      = 0 )\n\n# Syntax: <new_list> <- list(<initial values list name>) - Create list of all initial values\nlist_of_inits <- list(inits, inits, inits)\n```\n:::\n\n\n### brms SLR with Pseudo Vague Prior\n\nIn this example, we fit a \"pseudo-vague\" prior where $\\sigma^2 = 1000$ or, equivalently, $\\sigma = \\sqrt{1000} = 31.62278$. Here we call the prior \"pseudo-vague\" because it turns out that while it seems like a *large* variance, since $\\beta_0 \\sim N(\\mu=0, \\sigma=31.62278)$, there is some biasing towards a mean of 0.\n\n\n::: {.cell hash='index_cache/html/brms-slr-pseudo-vague-prior_6341080c9a4242ad19b7ecca3d50aece'}\n\n```{.r .cell-code}\nfit_lin_1 <-brm(in_phase_1_to_out_of_phase_2 ~ groupn,\n                data=trial,\n                family='gaussian',\n                prior = c(set_prior(\"normal(0,31.62278)\", class = \"b\"),\n                          set_prior(\"normal(0,31.62278)\", class =\"Intercept\"),\n                          set_prior(\"inv_gamma(0.01,0.01)\", class=\"sigma\")),\n                seed= 123,\n                init=list_of_inits,\n                warmup = 1000, iter = 10000, chains = 2, cores=4,\n                save_pars = save_pars(all = TRUE))\n\n# Summarize parameters\nsummary(fit_lin_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: in_phase_1_to_out_of_phase_2 ~ groupn \n   Data: trial (Number of observations: 66) \n  Draws: 2 chains, each with iter = 10000; warmup = 1000; thin = 1;\n         total post-warmup draws = 18000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    93.05      5.34    82.48   103.53 1.00    18799    13379\ngroupn        3.55      7.42   -10.90    18.16 1.00    17970    13260\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    30.71      2.75    25.89    36.59 1.00    19382    13421\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n# Obtain highest density posterior interval\nbayestestR::hdi(fit_lin_1, ci=0.95) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHighest Density Interval\n\nParameter   |          95% HDI\n------------------------------\n(Intercept) | [ 82.66, 103.66]\ngroupn      | [-10.79,  18.24]\n```\n:::\n\n```{.r .cell-code}\n# Syntax: plot() - print Bayesian diagnostic plots to console, plots in one figure\nplot(fit_lin_1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-pseudo-vague-prior-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Request plots individually \nmcmc_plot(fit_lin_1, type=\"hist\") #histogram\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-pseudo-vague-prior-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_1, type=\"trace\") #trace plot\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-pseudo-vague-prior-3.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_1, type=\"acf\") #autocorrelation plot\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-pseudo-vague-prior-4.png){width=672}\n:::\n\n```{.r .cell-code}\n# Syntax: prior_summary() - print priors used in console\nprior_summary(fit_lin_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                prior     class   coef group resp dpar nlpar lb ub       source\n   normal(0,31.62278)         b                                            user\n   normal(0,31.62278)         b groupn                             (vectorized)\n   normal(0,31.62278) Intercept                                            user\n inv_gamma(0.01,0.01)     sigma                               0            user\n```\n:::\n\n```{.r .cell-code}\n# Extract posterior chains\npost_samp <- as_draws(fit_lin_1)\n\n# Combine and extract drug group posterior estimates (can add more list items if more than 2 chains)\nxpost <- c(post_samp[[1]]$b_groupn, post_samp[[2]]$b_groupn) \n\n# Calculate the posterior probability that our group predictor is less than 0\nmean(xpost < 0) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3167222\n```\n:::\n:::\n\n\n### brms SLR with Vague Prior\n\nIn this example, we fit a \"vague\" prior where $\\sigma^2 = 10000$ or, equivalently, $\\sigma = \\sqrt{100} = 100$.\n\n\n::: {.cell hash='index_cache/html/brms-slr-vague-prior_c89a83358dcccf25fc0ef8f0135c4369'}\n\n```{.r .cell-code}\nfit_lin_2 <- brm(in_phase_1_to_out_of_phase_2 ~ groupn, \n                 data=trial, \n                 family='gaussian', \n                 prior = c(set_prior(\"normal(0,100)\", class = \"b\"),\n                           set_prior(\"normal(0,100)\", class = \"Intercept\"),\n                           set_prior(\"inv_gamma(0.01,0.01)\", class=\"sigma\")),\n                 seed= 123,\n                 init=list_of_inits,\n                 warmup = 1000, iter = 10000, chains = 2, cores=4)\n\nsummary(fit_lin_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: in_phase_1_to_out_of_phase_2 ~ groupn \n   Data: trial (Number of observations: 66) \n  Draws: 2 chains, each with iter = 10000; warmup = 1000; thin = 1;\n         total post-warmup draws = 18000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    94.28      5.43    83.71   105.04 1.00    16878    12729\ngroupn        3.63      7.60   -11.51    18.32 1.00    17708    11472\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    30.74      2.75    25.89    36.61 1.00    17210    13095\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nbayestestR::hdi(fit_lin_2, ci=0.95) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHighest Density Interval\n\nParameter   |          95% HDI\n------------------------------\n(Intercept) | [ 83.20, 104.45]\ngroupn      | [-11.06,  18.71]\n```\n:::\n\n```{.r .cell-code}\nplot(fit_lin_2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-vague-prior-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_2, type=\"hist\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-vague-prior-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_2, type=\"trace\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-vague-prior-3.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_2, type=\"acf\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-vague-prior-4.png){width=672}\n:::\n\n```{.r .cell-code}\nprior_summary(fit_lin_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                prior     class   coef group resp dpar nlpar lb ub       source\n        normal(0,100)         b                                            user\n        normal(0,100)         b groupn                             (vectorized)\n        normal(0,100) Intercept                                            user\n inv_gamma(0.01,0.01)     sigma                               0            user\n```\n:::\n\n```{.r .cell-code}\n# OPTION 1 for calculating posterior probabilities:\n# Extract posterior chains\npost_samp2 <- as_draws(fit_lin_2)\nxpost2 <- c(post_samp2[[1]]$b_groupn, post_samp2[[2]]$b_groupn) \n\n# Calculate the posterior probability that our group predictor is less than 0\nmean(xpost2 < 0) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3117778\n```\n:::\n\n```{.r .cell-code}\n# OPTION 2 for calculating posterior probabilities:\n# Extract posterior chains\npost_samp2 <- as_draws_df(fit_lin_2)\n\n# Create an indicator for group < 0\npost_samp2$indicator <- post_samp2$b_groupn<0\n\n# Calculate the posterior probability\nsummary(post_samp2$indicator)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Mode   FALSE    TRUE \nlogical   12388    5612 \n```\n:::\n:::\n\n\n### brms SLR with Optimistic Prior\n\nIn this example, we fit an \"optimistic\" prior on our treatment group such that $\\beta_1 \\sim N(\\mu=-30, \\sigma=10)$. This was selected based on the estimates used for the power analysis in the original trial where it was estimated that a clinically meaningful difference would be a 30 minute reduction in readiness to discharge.\n\n\n::: {.cell hash='index_cache/html/brms-slr-optimistic-prior_5421be8063a0f05e28e9d71aa1098a07'}\n\n```{.r .cell-code}\nfit_lin_3 <- brm(in_phase_1_to_out_of_phase_2 ~ groupn, \n                 data=trial, \n                 family='gaussian', \n                 prior = c(set_prior(\"normal(-30,10)\", class = \"b\", coef = \"groupn\"),\n                           set_prior(\"normal(0,100)\", class = \"Intercept\"),\n                           set_prior(\"inv_gamma(0.01,0.01)\", class=\"sigma\")),\n                 seed= 123,\n                 init=list_of_inits,\n                 warmup = 1000, iter = 10000, chains = 2, cores=4)\nsummary(fit_lin_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: in_phase_1_to_out_of_phase_2 ~ groupn \n   Data: trial (Number of observations: 66) \n  Draws: 2 chains, each with iter = 10000; warmup = 1000; thin = 1;\n         total post-warmup draws = 18000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   100.48      4.99    90.87   110.33 1.00    14460    12578\ngroupn       -8.79      6.24   -21.28     3.14 1.00    14788    12967\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    31.33      2.86    26.32    37.54 1.00    15824    13469\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nbayestestR::hdi(fit_lin_3, ci=0.95) #get 95% HDP Credible Intervals\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHighest Density Interval\n\nParameter   |          95% HDI\n------------------------------\n(Intercept) | [ 90.51, 109.89]\ngroupn      | [-20.89,   3.41]\n```\n:::\n\n```{.r .cell-code}\nplot(fit_lin_3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-optimistic-prior-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_3, type=\"hist\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-optimistic-prior-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_3, type=\"trace\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-optimistic-prior-3.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_3, type=\"acf\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-optimistic-prior-4.png){width=672}\n:::\n\n```{.r .cell-code}\nprior_summary(fit_lin_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                prior     class   coef group resp dpar nlpar lb ub  source\n               (flat)         b                                    default\n       normal(-30,10)         b groupn                                user\n        normal(0,100) Intercept                                       user\n inv_gamma(0.01,0.01)     sigma                               0       user\n```\n:::\n\n```{.r .cell-code}\n# Extract posterior chains\npost_samp3 <- as_draws(fit_lin_3)\n\nxpost3 <- c(post_samp3[[1]]$b_groupn, post_samp3[[2]]$b_groupn) \n\n# Calculate the posterior probability that our group predictor is less than 0\nmean(xpost3 < 0) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9235\n```\n:::\n:::\n\n\n### brms SLR with Skeptical Prior\n\nIn this example, we fit a \"skeptical\" prior on our treatment group such that $\\beta_1 \\sim N(\\mu=0, \\sigma=10)$. This prior represents a skeptics belief that there is a meaningful treatment difference by centering the treatment effect at 0 with smaller variance than our vague prior.\n\n\n::: {.cell hash='index_cache/html/brms-slr-skeptical-prior_f54dfb92a58de2cf6368f1a087582025'}\n\n```{.r .cell-code}\nfit_lin_4 <- brm(in_phase_1_to_out_of_phase_2 ~ groupn, \n                 data=trial, \n                 family='gaussian', \n                 prior = c(set_prior(\"normal(0,10)\", class = \"b\", coef = \"groupn\"),\n                           set_prior(\"normal(0,100)\", class = \"Intercept\"),\n                           set_prior(\"inv_gamma(0.01,0.01)\", class=\"sigma\")),\n                 seed= 123,\n                 init=list_of_inits,\n                 warmup = 1000, iter = 10000, chains = 2, cores=4)\n\nsummary(fit_lin_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: in_phase_1_to_out_of_phase_2 ~ groupn \n   Data: trial (Number of observations: 66) \n  Draws: 2 chains, each with iter = 10000; warmup = 1000; thin = 1;\n         total post-warmup draws = 18000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    94.95      4.92    85.27   104.53 1.00    18329    12418\ngroupn        2.27      5.98    -9.59    14.05 1.00    17125    13003\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    30.66      2.73    25.90    36.53 1.00    16139    13918\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nbayestestR::hdi(fit_lin_4, ci=0.95) #get 95% HDP Credible Intervals\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHighest Density Interval\n\nParameter   |         95% HDI\n-----------------------------\n(Intercept) | [85.18, 104.41]\ngroupn      | [-9.22,  14.32]\n```\n:::\n\n```{.r .cell-code}\nplot(fit_lin_4)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-skeptical-prior-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_4, type=\"hist\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-skeptical-prior-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_4, type=\"trace\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-skeptical-prior-3.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_plot(fit_lin_4, type=\"acf\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/brms-slr-skeptical-prior-4.png){width=672}\n:::\n\n```{.r .cell-code}\nprior_summary(fit_lin_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                prior     class   coef group resp dpar nlpar lb ub  source\n               (flat)         b                                    default\n         normal(0,10)         b groupn                                user\n        normal(0,100) Intercept                                       user\n inv_gamma(0.01,0.01)     sigma                               0       user\n```\n:::\n\n```{.r .cell-code}\n# Extract posterior chains\npost_samp4 <- as_draws(fit_lin_4)\n\nxpost4 <- c(post_samp4[[1]]$b_groupn, post_samp4[[2]]$b_groupn) \n\n# Calculate the posterior probability that our group predictor is less than 0\nmean(xpost4 < 0) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3480556\n```\n:::\n:::\n\n\n# References\n\nBelow are some references to highlight based on the slides and code:\n\n-   [A practical guide to adopting Bayesian analyses in clinical research](https://www.cambridge.org/core/journals/journal-of-clinical-and-translational-science/article/practical-guide-to-adopting-bayesian-analyses-in-clinical-research/CF6C017318CD5431C98EEFE37DBB6063?utm_campaign=shareaholic&utm_medium=copy_link&utm_source=bookmark): 2024 tutorial paper exploring the Bayesian approach to statistics and how to apply the methods for clinical trials\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}